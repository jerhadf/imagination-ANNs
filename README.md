= Imagination in Artificial Neural Networks =
by Jeremy Hadfield

This article focuses on how imagination can be modeled computationally and implemented in artificial neural networks. Pursuing artificial imagination - the attempt to realize imagination in computer and information systems - may supplement the creative process, enhance computational tools and methods, and improve scientific theories of the cognitive and neural underpinnings of human imagination, mental simulation and imagery, hallucinations, and perception. There are a wide variety of computational mechanisms and architectures that replicate, implement, or employ some kind of imagination, almost all of which involve artificial neural networks. Artificial imagination also has substantial ethical, social, and economic consequences. 

[[File:artificial_imagination_art.jpg|450px|right|thumb|none|An artistic visualization of artificial imagination, created by [https://gabrielsilveira.com/scientific-american-artificial-imagination Gabriel Silveira] for Scientific American.]] 

== Definitions and Concepts == 
[https://en.wikipedia.org/wiki/Creativity Creativity] is the process of producing ideas, artifacts, or concepts that are both novel and valuable. [https://en.wikipedia.org/wiki/Imagination Imagination] is the ability to produce and/or simulate new objects, sensations, or ideas in the mind. Imagination can be understood as both a sub-process within creativity and as a semi-separate capacity that supports creative generation.  As the initial generative step in creativity, imagination produces the creative possibilities that are then considered, evaluated, and implemented by other systems. Imagination produces internal representations that will not necessarily be novel or useful (creative), but that can provide a fertile starting point for the creative process. Therefore, most computationally creative systems will incorporate a mechanism of imagination, even if it is not modelled directly. This present article focuses on the imagination specifically, viewed within the broader context of creativity. 

=== Defining imagination === 
The term "imagination" presents a challenge for researchers, since it is used colloquially in a variety of ways, its meaning is the subject of intense debates in philosophy and other fields, and "imagination" does not have an agreed-upon formalized definition in mathematics, computer science, or cognitive science. However, a '''minimal shared concept of imagination''' abstracts from the many sub-types, from mental imagery of visual scenes to propositional supposing, and enables collaborative research. Specifically, imagination is mental simulation: the ability to simulate non-occurrent possibilities, representing something in the mind without aiming to capture things as they actually are in the moment. In other words, imagination is to “represent without aiming at things as they actually, presently, and subjectively are.” <ref> Liao, Shen-yi and Tamar Gendler, “Imagination,” The Stanford Encyclopedia of Philosophy. </ref> Thus, imagination can be understood as a form of "attention to possibilities," where potential realities are projected, simulated, and operated upon internally.<ref> Williamson, Timothy, “Knowing by imagining,” Knowledge through imagination (2016): 113-23. Pg. 4. </ref> Imagination often involves representing a complete situation, “a configuration of objects, properties, and relations," rather than a single isolated object.<ref> Berto, Francesco. "Taming the runabout imagination ticket." Synthese (2018): 1-15.</ref> Imagination is involved in a wide range of cognitive processes, including memory, predicting the future, conjuring alternate worlds, simulating and empathizing with other minds, spatial navigation, and inventing novel combinations of images and objects. 

=== The imagination in computation === 
In computational terms, imagination refers to a system's processing of information that is not directly present to the system's sensors.<ref> Marques, H. G., & Holland, O. (2009). Architectures for functional imagination. Neurocomputing, 72(4-6), 743-759. </ref> This 'imaginative' processing will occur offline (when the agent is not receiving new sensory data from outside or not connected to the environment it operates within), covertly (without immediate consequences for the agent's actions), and/or internally (occurring within the agent's own latent models). Any artificial system capable of imagination should be able to monitor its environment and respond to unexpected situations. In robotics, imagination is understood as the internally simulated interaction of an agent with the environment. This is based on the '''perceptual activity theory,''' which argues that new knowledge and understanding are primarily generated by the synthesis of perception and imagination.<ref>Thomas, N. J. (1999). Are theories of imagery theories of imagination? An active perception approach to conscious mental content. Cognitive science, 23(2), 207-245.</ref> For a robot capable of imagination, perceptual experience consists of the ongoing activity of schema-guided perceptual exploration of the environment. 

=== Functional imagination === 
'''Functional imagination''' is a widely-used concept in the computational research, and describes any mechanism that allows an agent to simulate its own actions and their sensory consequences internally and extract behavioral benefits from these simulations.<ref> Marques, H. G., & Holland, O. (2009). </ref> This requires the system to have the ability to (1) represent alternative sensory states, (2) predict future sensory states given an action and a current state, (3) represent behavioral goals, (4) evaluate whether goals are achieved, and (5) select an action to achieve these goals. This implies a '''corresponding architecture''' to achieve these abilities. For example, the agent must have a sensory system, the motor system, a forward model for prediction, an evaluation mechanism, a goal buffer, an action-selection mechanism, and a ''switch'': a mechanism that allows the agent to transition between executing actions in the real world and in its internal models, requiring inhibition of sensory input and motor output. A typical system with functional imagination involves a logical loop: (1) compare the current state to a goal state; (2) if the goal state is not satisfied, turn the switch off; (3) select a series of prospective actions and simulate the resulting states; (4) if the resulting state matches the goal, turn the switch on and execute the action overtly, repeating this process until the goal is reached. Many computer systems and ANNs exhibit ''functional'' imagination even if they do not involve internal imagery or other features that are typically attributed to the folk idea of "imagination."

=== Artificial neural networks ===
[[File:Artificialneuralnetwork.jpg|200px|right|thumb|none|A schematic diagram of a simple ANN.]]
Finally, an [https://en.wikipedia.org/wiki/Artificial_neural_network artificial neural network] (ANN) is a kind of formal structure based on biological neurons, consisting of layers composed of nodes (artificial neurons) that are connected by weighted edges analogous to synaptic connections. The artificial neurons apply a mathematical function to the weighted sum of its inputs, and then transmits the output of this function to the next layer. ANNs include an input layer, at least one hidden layer, and an output layer. This architecture facilitates recognizing patterns in inputs and modeling complex relationships between inputs and outputs.

== Background ==
Several fields involve the computational study of imagination. '''[https://en.wikipedia.org/wiki/Computational_creativity Computational creativity]''' is a multidisciplinary field that aims to replicate human-level creativity in computer systems, better understand human creative abilities with computational models, and enhance human creativity with computer tools. '''[https://en.wikipedia.org/wiki/Artificial_imagination Artificial imagination]''' is both a property of some computer systems and programs, and a subfield of computational creativity which is focused on simulating human-level imagination in computers, artificial neural networks, or other information systems. This field is also called '''computational imagination''', a term that is sometimes used to emphasize computationally modeling human imagination rather than implementing it in computers. The pursuit of artificial imagination can simultaneously advance the computer science of neural networks by applying techniques inspired by the imagination, and encourage progress in the neuroscience of imagination with insights from computational models and applications. 

=== Computational Imagination === 
The field of computational imagination has a research agenda with three primary challenging goals:<ref>Setchi, R., Lagos, N., & Froud, D. (2007, December). Computational imagination: research agenda. In Australasian Joint Conference on Artificial Intelligence (pp. 387-393). Springer, Berlin, Heidelberg.</ref>

# '''Establish the theoretical groundwork of computational imagination''' with definitions, metrics, and conceptual or formal models. A conceptual model could represent the abstract concepts and relations associated with the mental images is by using image schemata and conceptual metaphors, and a formal model could symbolically or mathematically represent the components and processes of the imagination. 
# '''Identify the computational foundations of imagination''' by developing models and algorithms for generating imaginings. This involves developing new reasoning techniques to support generating sequences of imagined possibilities in visual, linguistic, motor, and other modalities. Further, it requires implementing these techniques in algorithms, computational models, and/or artificial neural networks. 
# '''Validate the developed computational and theoretical models''' using purpose-built simulations, tests, and experiments. 

By pursuing these agendas, researchers can better understand the interactions between imagination and other cognitive or affective processes; analyze the way perceptions, emotions, prior knowledge, context, and social factors influence imagination; and design agents that can form concepts or images of things that are neither perceived or sensed as presently real.

=== History === 
[[File:Googlengram creativity.png|1000px|thumb|none|A visualization of interest in computational creativity and artificial imagination, created using the Google Engram Viewer based on a corpus of English books from 1800 to 2019. This shows that these fields began in the 1980s along with the development of artificial neural networks, and interest surged in the 2000s.]] 

The question of whether machines can imagine has occupied thinkers for centuries. In ''How to build a mind: toward machines with imagination,'' Igor Alexander traces the history of thought on computational imagination from early Greek philosophy to Turing to modern ANNs.<ref> Aleksander, Igor (2001). How to build a mind: toward machines with imagination. Columbia University Press.</ref> However, the earliest attempts to develop computer models on imagery began in the 1970s, and hinged on the arguments between two main advocates for opposing camps on the '''imagery debate,''' which asks whether the imagination forms (or represents) ''ideas'' or ''images''.<ref>Pylyshyn, Z., & Dupoux, E. (2001). Is the imagery debate over? If so, what was it about. Language, brain, and cognitive development: essays in honor of Jacques Mehler. MIT Press, Cambridge, MA, 59-83.</ref> The '''description theory,''' advocated by Pylyshyn<ref>Pylyshyn, Z.W.: Computation and Cognition. MIT Press, Cambridge (1984)</ref>, posits that imaginings are more like ideas, structured language-based descriptions with encodings and syntactical instructions. On the other hand, '''picture theory,''' defended by Kosslyn<ref> Kosslyn, S.M., Pomerantz, J.R.: Imagery, Propositions, and the Form of Internal Representations. Cognitive Psychology 9, 52–76 (1977)</ref>, argues that the imagination represents mental images, quasi-pictures in the mind. 

Of course, the outcome of this debate has significant implications for how imagination should be modeled computationally. Computer models based on the picture theory will emphasize extracting features from images, forming implicit or symbolic representations of these images, and then generating visual artifacts. Models inspired by description theory will instead emphasize the semi-deterministic production of logical objects. 

Mueller, another early researcher, pitched camp away from the imagery debate, focusing instead on the way imagination influences and is influenced by emotions, and how [https://en.wikipedia.org/wiki/Affective_computing affective computing] can inform imagined models of our own subjective state, the feelings of others, and social interactions. In his seminal works starting in 1985, Mueller created a '''computational model of human daydreaming''' that involved a scenario generator, a dynamic episode memory of experiences, a collection of goals to guide the generator, emotional states that guide goals and initiate daydreams, and domain knowledge of interpersonal relations and everyday occurrences.<ref> Mueller, E. T., & Dyer, M. G. (1985). Towards a computational theory of human daydreaming. Cognitive Science Society.</ref><ref> Mueller, E. T. (1990). Daydreaming in humans and machines: a computer model of the stream of thought. Intellect Books.</ref>This study points toward the '''central role of emotions in modulating imagination'''. Affects and imaginings both occur in a shared internal space, and imaginings are often started by emotions and result in changed affective states. 

Ultimately, the '''imagery debate was largely resolved''' by a shared understanding that imagination can involve many heterogenous types of representations, including images to symbolic linguistic structures.<ref> Pearson, J., & Kosslyn, S. M. (2015). The heterogeneity of mental representation: Ending the imagery debate. Proceedings of the National Academy of Sciences, 112(33), 10089-10092.</ref> While current inquiry largely bypasses this debate and explores many kinds of imagined representations, the dispute was a fruitful beginning that led to a flurry of research to model and understand the imagination.

By the 1990s, machine learning researchers were attempting to use ANNs to replicate human-level imaginative and creative abilities. For example, Peter Todd in 1989 helped pioneer the use of imagination in non-visual domains by training a neural network to reproduce musical melodies from a training set of musical pieces.<ref>Todd, P. M. (1989). A connectionist approach to algorithmic composition. Computer Music Journal, 13(4), 27-43.</ref> This method showed that artificial neural networks could learn the structure of auditory samples and generalize these learned structures to generate new pieces. Subsequently, similar approaches were applied to a wide variety of problem domains and representation types.

== Computational Models of Imagination == 
Computational tools like ANNs can be used to model the cognitive and neural dynamics of the human imagination. ANNs were originally inspired by the human brain, and a tremendous amount of evidence shows that '''ANNs are uniquely suited for formalizing and simulating neurobiological functions and structures'''.<ref> Zorins, A., & Grabusts, P. (2015, June). Artificial neural networks and human brain: survey of improvement possibilities of learning. In ENVIRONMENT. TECHNOLOGIES. RESOURCES. Proceedings of the International Scientific and Practical Conference (Vol. 3, pp. 228-231).</ref> As the imagination is a complex cognitive function that is realized in brain activity, ANNs and other computational tools can be fruitfully applied to model and simulate it. Even features of human cognition that seem mysterious, like intuition, imagery, daydreaming, insight, and creativity, are a consequence of information processing in complex networks.<ref>Duch, W. (2007). Intuition, insight, imagination and creativity. IEEE Computational Intelligence Magazine, 2(3), 40-52. </ref> This section reviews computational models of the imagination. Machine learning models of imagination are often inspired by neuroscientific findings, and these computational models in turn inform research into the neurobiological implementation and cognitive architecture of imagination. 

Of course, the '''imagination is only one part of a complex cognitive neural and cognitive system'''. Models that focus on the imagination in isolation will inevitably omit other relevant parts of the human information system, and thus cannot perfectly replicate it. Still, an emphasis on the imagination allows researchers to understand it as a distinct faculty, its purpose in the brain, and its underlying computational mechanisms. These models of imagination could then later be integrated into larger and more complex simulations of the entire cognitive architecture. 

=== Neural Network Models of Imagination === 
Many of the computations, mechanisms, and representations involved in imagination can be mimicked or duplicated with neural networks. For example, AI algorithms in '''convolutional neural networks (CNNs) can implement visual blending processes''' analogous to the combining of images that occurs in human imagination.<ref> McCaig, G., DiPaola, S., & Gabora, L. (2016). Deep convolutional networks as models of generalization and blending within visual creativity. arXiv preprint arXiv:1610.02478.</ref> Similarly, neural networks can implement [https://en.wikipedia.org/wiki/Conceptual_blending conceptual blending], a posited mechanism of human creativity, to produce creative artifacts like fictional narratives.<ref> Li, B., Zook, A., Davis, N., & Riedl, M. O. (2012, May). Goal-driven conceptual blending: A computational approach for creativity. In Proceedings of the 2012 International Conference on Computational Creativity, Dublin, Ireland (pp. 3-16). </ref> Thagard et al (2011) show that creativity can arise computationally by combining neural patterns into new (potentially novel & useful) representations using an operation like [https://en.wikipedia.org/wiki/Convolution convolution], which interweaves or 'twists together' the neural activity patterns.<ref> Thagard, P., & Stewart, T. C. (2011). The AHA! experience: Creativity through emergent binding in neural networks. Cognitive science, 35(1), 1-33.</ref> The authors use computer simulations to show that neural patterns can be represented as vectors, convolution can be performed by the synaptic connection weights that implement the neural pattern, and this combination can be multimodal (e.g. integrating visual and audio representations). When this new representation is valuable but unexpected, surprising, in novel, it results in an emotional "AHA!" experience. 

The generative abilities of deep neural networks (DNNs) are incredible, but '''DNNs are often hard-to-interpret black boxes''', where creative behavior is not programmed explicitly but emerges from the interaction of computational networks. To explain DNNs more clearly, Wyse (2019) reviews 5 behavioral characteristics of human creativity - transformative perception, multiple-domain synthesis, sentiment recognition and synthesis, transformation abstraction, and metaphorical reasoning - and explains how they are implemented through computational mechanisms in DNNs.<ref> Wyse, L. (2019). Mechanisms of artistic creativity in deep learning neural networks. arXiv preprint arXiv:1907.00321.</ref> For instance, '''DNNs can achieve transformative perception''' (making an image new or seeing it in a unique way) by performing activation maximization, where hidden units of the NN are monitored and input images are manipulated to amplify response patterns of certain units. In this way, the ANN learns how the image can be changed to produce new images, encoding the image's implicit structure, so that it can then generate novel images based on the connections it learned during training. 

[[File:AssociativeConceptualImagination.png|400px|right|thumb|none|An overview of the Associative Conceptual Imagination framework. A vector space model learns, from a large corpus, how to encode semantic information into concept vectors, and then associative memory models learn to associate these concept vectors and example artifacts. The semantic structure encoded in concept vectors allows the framework to imagine never-before-seen artifacts.]] 
'''Not all models of imagination require using ANNs.''' For instance, '''SOILIE (Science of Imagination Laboratory Imagination Engine)''' is a computational model of the 2D visual imagination, consisting of a database of labeled images and words associated together when co-appear as labels, which can then recreate an image of the inputted words along with a scene composed of similar images.<ref> Breault, V., Ouellet, S., Somers, S., & Davies, J. (2013). SOILIE: A computational model of 2D visual imagination. In Proceedings of the 12th International Conference on Cognitive Modeling (pp. 95-100).</ref> SOILIE is based on three elements - a database of image-word associations, a model that compresses this database into a feature space organized by semantic similarity, and a renderer. Another similar model of imagination is the '''Associative Conceptual Imagination (ACI)''', which learns conceptual knowledge and associations using associative memory models (AMMs) and vector space models (VSMs) to imagine & create novel interesting artifacts<ref> Heath, D., Dennis, A. W., & Ventura, D. (2015). Imagining Imagination: A Computational Framework Using Associative Memory Models and Vector Space Models. In ICCC (pp. 244-251).</ref> ACI could facilitate the imagining of distortions to existing concepts by gradually venturing away from a concept’s vector along different dimensions. However, these simple associational models of imagination cannot replicate the human capacity to recombine images and generate novel ones. 

==== DeepDream as a Model of Imagination ====
[[File:DeepDream examples.png|300px|right|thumb|none|A example of a complex image generated with DeepDream.]] 

[[File:Deepdreamalgorithm.png|500px|left|thumb|none|A schematic of the computational architecture of the DeepDream CNN.]] 

[https://en.wikipedia.org/wiki/DeepDream DeepDream] is a convolutional neural network (CNN) that generates a transformed version of a source image, emphasizing certain visual (semantic and/or stylistic) qualities.<ref> Mordvintsev, Alexander; Olah, Christopher; Tyka, Mike (2015). "DeepDream - a code example for visualizing Neural Networks". Google Research.</ref> Higher layers in the network encode the image in progressively more abstract features, and a loss function compares feature vectors between input and output features. This maximizes the dot product between source and guide features, and can create exaggerated hallucinatory features. "Dreaming" in this context refers to the process of generating images to produce the desired activations in a deep neural network. 

Hallucination is similar to imagination, and both processes can guide creativity and artistic production by allowing one to see in an unusual way. Berov & Kuhnberger show that '''DeepDream, as a method for visualizing the feature space of CNNs, is an effective model of hallucination''' <ref> Berov, L., & Kuhnberger, K. U. (2016, June). Visual hallucination for computational creation. In Proceedings of the Seventh International Conference on Computational Creativity. </ref> Similar to hallucination, the DeepDream algorithm involves enhancing features present in the input in a [https://en.wikipedia.org/wiki/Pareidolia pareidolic] way, amplifying the activity of one subsystem of the network to create visual representations more correlated to high-level knowledge than the input image. DeepDream even supports a kind of "guided dreaming," where a guiding image is forward-propagated through the CNN along with the input image, and the network aims to optimize the dot product of input-image & guiding-image activation at each layer - ensuring that features of both images are enhanced. Furthermore, Suzuki et al (2017) shows that Deep Dream and virtual reality can be combined to create a "'''hallucination machine'''," which replicates the phenomenology of human altered states and hallucinations.<ref> Suzuki, K., Roseboom, W., Schwartzman, D. J., & Seth, A. K. (2017). A deep-dream virtual reality platform for studying altered perceptual phenomenology. Scientific reports, 7(1), 1-11.</ref> These are compelling examples of using ANNs to simulate human visualization processes. 

DiPaola et al (2018) also show that '''DeepDream-based CNNs can implement computational art rendering based on cognitive theories of creativity'''.<ref> DiPaola, S., Gabora, L., & McCaig, G. (2018). Informing artificial intelligence generative techniques using cognitive theories of human creativity. Procedia computer science, 145, 158-168. </ref> The processes of conceptual and visual blending and contextual focus switching can be replicated in DeepDream. Further, [https://en.wikipedia.org/wiki/Creativity#Honing_theory honing theories] predict that creativity results from the merging of memory items into a single ill-defined cognitive structure that becomes honed into an increasingly well-defined representation through interaction with the environment. In support of this theory, Hélie et al (2010) show that creative problem-solving consists of the interaction, integration, and simultaneous involvement between implicit and explicit representations, and this can be computationally modeled with the [https://en.wikipedia.org/wiki/CLARION_(cognitive_architecture) CLARION cognitive architecture.] <ref> Hélie, S., & Sun, R. (2010). Incubation, insight, and creative problem solving: a unified theory and a connectionist model. Psychological review, 117(3), 994. </ref> This honing occurs in DeepDream, where guide images play the role of memories and source images are the problem for creative solution, and the network iteratively explores the space of potential associations between these two to progressively enhance the most resonant features and produce a creative output.

==== Imagination and Motor Learning ====
Findings from research with ANNs shows that agents can learn successful motor policies by training on a simulated model of the environment alone, without needing actual sensory input.Ziemke et al (2005) shows that robots can implement internal simulation, exhibiting (1) covert internal behavior, (2) imagery or simulated experience, and (3) anticipating the sensory consequences of motor action.<ref> Ziemke, T., Jirenhed, D. A., & Hesslow, G. (2005). Internal simulation of perception: a minimal neuro-robotic model. Neurocomputing, 68, 85-104.</ref> The robot can learn successful navigation behaviors based only on the robot's predictions about sensor states during simulation. Their work is inspired by the '''simulation hypothesis of human cognition''', which claims that the neural structures involved in perception and initiation of overt behavior are also responsible for covert behavior and mental imagery, and thinking is simulated interaction with the environment.<ref>Hesslow, G. (2012). The current status of the simulation theory of cognition. Brain research, 1428, 71-79.</ref> This suggests that humans and other animals, who are also embodied agents, can also learn by simulation.  <ref>Vedantam, R., Fischer, I., Huang, J., & Murphy, K. (2017). Generative models of visually grounded imagination. arXiv preprint arXiv:1705.10762.</ref> Additionally, [https://en.wikipedia.org/wiki/Place_cells place cells] in the rat hippocampus generate brief sequences that encode a possible spatial trajectories during a navigation task, enabling the rat to associate imagined places in the route with future value or the goal destination.<ref> Pfeiffer, B. E., & Foster, D. J. (2013). Hippocampal place-cell sequences depict future paths to remembered goals. Nature, 497(7447), 74-79.</ref> Later sections will show that this neural mechanism is similar to imagination-augmented methods for reinforcement learning. 

If the human imagination is analogous to the artificial imagination, humans should also be able to learn from internal simulations. Indeed, substantial research shows that humans not only use the imagination to plan and visualize future actions, but can use mental simulations to learn and improve motor skills.<ref>Jeannerod, M., & Frak, V. (1999). Mental imaging of motor activity in humans. Current opinion in neurobiology, 9(6), 735-739.</ref><ref> Sheahan, H. R., Ingram, J. N., Žalalytė, G. M., & Wolpert, D. M. (2018). Imagery of movements immediately following performance allows learning of motor skills that interfere. Scientific reports, 8(1), 1-12.</ref><ref> Van Leeuwen, R., & Inglis, T. J. (1998). Mental practice and imagery: a potential role in stroke rehabilitation. Physical therapy reviews, 3(1), 47-52.</ref>

=== Imagination as a Generative Model ===
[[File:Gen_discriminative_models.jpg|400px|right|thumb|none|An illustration of the difference between generative & discriminative models.]] 
A '''[https://en.wikipedia.org/wiki/Generative_model generative model]''' is a type of statistical model that estimates the probability distribution of an observed variable given a target variable, in contrast to '''[https://en.wikipedia.org/wiki/Discriminative_model discriminative models]''' that estimate a target variable's probability distribution based on observed variables. In other words, a generative model simulates the interactions among unobserved variables that might generate the observed variables. Rather than just creating input-output mappings or categorizing a signal, generative algorithms attempt to figure out how the data was generated to classify it, asking which target category is most likely to have produced the observation. By understanding the methods of generation, these models can also create new data similar to the observed data. '''Deep generative models''' use deep neural networks to force the models to internalize an abstracted, simplified essence of the data.  For example, graphics rendering programs can follow a set of processes to simulate a physical environment. In the context of [https://en.wikipedia.org/wiki/Markov_decision_process#Simulator_models Markov decision processes], "generative model" refers to a simulator that generates samples of the next possible state and reward in an environment given any state and action. 

Williams (2020) provides detailed arguments to show that '''imagination and perception are best described as generative models'''.<ref> Williams, D. (2021). Imaginative constraints and generative models. Australasian Journal of Philosophy, 99(1), 68-82.</ref> Discriminative models are unable to explain top-down effects in perception (where higher-level representations impact processing of early info) or endogenously generated percepts like mental imagery and dreams (which have no clear inputs for classification). Generative models correlate to the widely-accepted [https://en.wikipedia.org/wiki/Predictive_coding predictive processing] framework in neuroscience, as they are prolific expectation-generators that allow continuous predictions of incoming sensory information based on estimates of their external causes. The brain likely uses temporal generative models to which use current observations and perceptual history to make inferences and find dependencies in input patterns that appear in timed order, to predict its future sensory stream. The imagination co-opts this predictive capacity of perception and re-uses its core representational architecture, modifying our implicit, learned representations of the dynamics of the real world to generate imagined worlds with new or altered dynamics. Extensive evidence supports the theory that the brain uses a hierarchical generative model to “minimize prediction error in the cascade of cortical processing,” and higher-level areas can use these generative models to drive lower neural populations into predicted patterns and produce internal perception. <ref> Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral and brain sciences, 36(3), 181-204. </ref> Thus, the cortex likely implements a generative model to explain, predict, and learn about sensory data, and then cross-applies this model to synthesize rich visual representations without external input. 

Treating imagination as a generative model is valuable for a few additional reasons. First, '''imagination is governed by principles of generation''': a set of (implicit or explicit) rules that guide our imaginings.<ref> Walton, Kendall L, Mimesis as make-believe: On the foundations of the representational arts, Harvard University Press, 1990. Pg. 53. </ref> For example, in Harry Potter, “Latin words and wands create magic” is a principle of generation that readers can consistently use to simulate the imagined world. The imagination generates a set of possibilities guided by context-relevant principles, like graphics rendering algorithms that unfold an artificial world procedurally using algorithmic rules. Treating imagination as a generative model also explains imaginative mirroring: our imagination defaults to follow the rules of the real world unless prompted otherwise by principles of generation.<ref> Leslie, Alan M, “Pretending and believing: Issues in the theory of ToMM,” Cognition 50, no. 1-3 (1994): 211-238. </ref> If a cup ‘spills’ in an imaginary tea party, the participants will treat the spilled cup as empty, following the physics of reality. This occurs because perception involves generative models, using processes we derive from experience to simulate the physical world and predict its behavior. '''Imagination involves running a generative model 'alongside' or 'on top' of this simulation of reality'''. Some processes are modified in the imagining, but the ones that are not modified are ‘filled in’ by our default generative model of the real world. 

==== Generative Models for Explaining Mental Imagery and Its Pathologies ====
[[File:DBM architecture.png|300px|right|thumb|none|The architecture of a Deep Boltzmann Machine, where a series of symmetric layers with unconnected internal nodes are connected to learn the probability distribution over the inputs.]]
Generative models can be implemented computationally to model imagination. For instance, Testolin & Zorzi (2016) show that human perception is analogous to graphical models implemented with stochastic generative neural networks, which build high-level representations and extract statistical regularities from the environment in an unsupervised way, and use feedback connections to carry-top down expectations.<ref> Testolin, A., & Zorzi, M. (2016). Probabilistic models and generative neural networks: Towards an unified framework for modeling normal and impaired neurocognitive functions. Frontiers in Computational Neuroscience, 10, 73. </ref> These '''generative models have psychologically and biologically plausible properties''', like unsupervised learning and interactions between feedback and feed-forward activity.

Using generative models to explain human internal imagery is demonstrated in Reichert et al (2013), which shows that the dynamics of [https://en.wikipedia.org/wiki/Visual_release_hallucinations '''hallucinations in Charles Bonnett syndrome]''' (CBS) can be simulated and explained by a generative model implemented with a '''[https://en.wikipedia.org/wiki/Boltzmann_machine Deep Boltzmann machine]''' (DBM).<ref>Reichert, D. P., Series, P., & Storkey, A. J. (2013). Charles Bonnet syndrome: evidence for a generative model in the cortex?. PLoS computational biology, 9(7), e1003134.</ref> In CBS, partial blindness results in a deficiency of visual input in early processing stages, resulting in spontaneous activity in the cortex. The authors show that recurrent connections between layers in DBMs are similar to reciprocal synaptic connections between layers in the neural visual processing hierarchy, and enable simulating the balance between bottom-up sensory information and top-down internal priors that occurs in the brain. Further, the artificial neurons of the DBM can replicate the neural homeostatic adaptation, where neurons adapt their excitability toward a target activity level. Finally, DBMs can model the role of [https://en.wikipedia.org/wiki/Acetylcholine acetylcholine] (ACh) in neural information processing - ACh mediates the balance between external & internal input, helping switch between upstream sensory input and downstream inputs, and can be modeled in the DBM as a balance factor that affects how much an intermediate layer influenced by other layers. When the trained DBM is given empty or corrupted input, this results in artificial hallucinations that can be strikingly decoupled or contradictory from the input image. Similarly, a [https://en.wikipedia.org/wiki/Hopfield_network Hopfield network] can be used to model the dynamics of hallucinations in schizophrenia.<ref>Ruppin, E., Reggia, J. A., & Horn, D. (1996). Pathogenesis of schizophrenic delusions and hallucinations: a neural model. Schizophrenia bulletin, 22(1), 105-121.</ref> 

Furthermore, generative models extend to normal perception: Lee et al (2008) shows that a sparse deep belief network can model the dynamics of visual area V2.<ref> Lee H, Ekanadham C, Ng AY (2008) Sparse deep belief net model for visual area V2. Advances in Neural Information Processing Systems 20.</ref> Variational auto-encoders can also be used as '''generative models for the visual imagination''', visualizing objects that the network has never seen before and replicating the correctness, coverage, and compositionality of human imagination.<ref>Vedantam, R., Fischer, I., Huang, J., & Murphy, K. (2017).</ref> Finally, Testolin et al (2016) shows that recurrent, temporally-restricted DBMs that extract high-level structure from time-sequenced visual data are an excellent model of neural computation, where the brain produces expectations to sharpen and improve early visual processing.<ref> Testolin, A., Stoianov, I., Sperduti, A., & Zorzi, M. (2016). Learning orthographic structure with sequential generative neural networks. Cognitive Science, 40(3), 579-606.</ref> These examples are fascinating demonstrations of the potential of using generative models to facilitate progress in understanding the mechanisms of hallucinations, mental imagery, and perception in the human brain.

=== The Dual-Process Model of Creativity ===
[[File:Dualprocess.png|500px|right|thumb|none|A comparison of the generative and evaluative processes in creativity.]]
In the dual-process model, creative thinking involves an '''initial phase of unconstrained generation''' or brainstorming, and a subsequent more-constrained and '''systematic evaluation''' that explores and tests these crude associations.<ref>https://jeremyhadfield.com/sparks-of-generative-creativity-in-mental-disorders</ref> The generative phase corresponds to imagination, while the evaluative phase involves critical thinking, executive function, and practical tests. Computationally, a generatively creative system is one that creates new patterns regardless of their estimated benefit to the system, while evaluative or adaptive creativity involves creating patterns that fulfill established value-functions.<ref>Bown, O. (2012). Generative and adaptive creativity: A unified approach to creativity in nature, humans and machines. In Computers and creativity (pp. 361-381). Springer, Berlin, Heidelberg.</ref> Evidence suggests that the dual-process model has a basis in the brain, as the two phases (generation and evaluation) involve distinct neural systems: creative generation recruits primarily the default mode networks and medial temporal lobe regions like the hippocampus, while evaluation co-recruits the default mode and executive control networks.<ref>Ellamil, M., Dobson, C., Beeman, M., & Christoff, K. (2012). Evaluative and generative modes of thought during the creative process. Neuroimage, 59(2), 1783-1794. https://doi.org/10.1016/j.neuroimage.2011.08.008</ref> Furthermore, the generative and evaluative networks are competitive: “the more successfully [participants] were able to engage in creative generation while avoiding evaluative processes, the more they recruited MTL regions associated with creative generation.”<ref>Ellamil 2012.</ref> These phases are both vital to successful creative production, but they are underpinned by diverging cognitive styles and neural correlates. 

The dual-process theory suggests that any computational model of creative imagination must involve multiple components, including a generator and an evaluator.  After all, it is hard for an agent to imagine valuable possibilities if it cannot evaluate them. Arguably, a creative system must be able to perceptually evaluate its own artifacts, or it will not have a real understanding of if, why, or how it is creative. Enhancing its perceptual abilities could make a system more creative, more autonomous, improve its artifact-evaluation, and give  better internal models - and deep learning approaches to image generation show the creative potential of systems with advanced perceptual abilities.<ref> Heath, D., & Ventura, D. (2016, June). Before a computer can draw, it must first learn to see. In Proceedings of the 7th international conference on computational creativity (pp. 172-179).</ref> As Michelangelo writes, “we create by perceiving and that perception itself is an act of imagination and is the stuff of creativity.”<ref> Wyse 2019</ref> As this article will discuss later, the dual-process theory points naturally towards generative adversarial networks as a model of imagination. However, many ANNs also involve interactions between generative (bottom-up) and evaluative (top-down) units. 

=== Connections to the Neuroscience of the Imagination ===
This article primarily aims to describe imagination on [https://en.wikipedia.org/wiki/Level_of_analysis#Level_of_analysis_in_cognitive_science Marr’s computational and algorithmic levels of analysis], without delving into the details of neural implementation. However, any complete model of imagination will accurately describe how it is produced by complex interactions of neuron assemblies in the human brain. How do neural circuits create a representation of an object that is not currently present in the subject’s sensory environment? 

[[File:Imagination_DMN.png|300px|right|thumb|none|The structure of connections in the Default Mode Network, the brain network involved in imagining the future, remembering the past, daydreaming, and counterfactual thinking.]] 
There is a growing consensus that remembering the past, imagining the future, and counterfactual thinking all involve similar neural mechanisms in the default mode network (DMN).<ref>Mullally, Sinéad L., and Eleanor A. Maguire, “Memory, imagination, and predicting the future: a common brain mechanism?” The Neuroscientist 20, no. 3 (2014): 220-234.</ref> More specifically, future-oriented and counterfactual thinking engages the posterior DMN (pDMN), centered around the posterior cingulate cortex.<ref> Xu, Xiaoxiao, Hong Yuan, and Xu Lei, “Activation and connectivity within the default mode network contribute independently to future-oriented thought,” Scientific reports 6 (2016): 21001. </ref> Researchers showed this by asking participants in an fMRI scan to make choices about their present situation, and then prospective choices about their future. Their findings demonstrated that people often engage vivid mental imagery in future-oriented thinking, and that this process activates the pDMN while reducing its connectivity with the anterior DMN. This provides a candidate neural process that underlies imaginative generation of possibilities. Furthermore, a key cognitive ability that underlies imagination is prefrontal synthesis (PFS), the ability to create novel mental images. This process is performed in the lateral prefrontal cortex (LPFC), which likely acts as an executive controller that synchronizes a network of neuronal ensembles that represent familiar objects, synthesizing these objects into a new imaginary experience.<ref> Vyshedskiy, Andrey. "Neuroscience of imagination and implications for human evolution." (2019). Preprint DOI: 10.31234/osf.io/skxwc. </ref> Imagination can be either top-down and intentional, driven by the prefrontal cortex synchronization of lower-level neuronal assemblies, or bottom up and unintentional, when lower-level ensembles synchronize non-volitionally to produce dreams, hallucinations, or sudden insights. 

A core connection between imagination and ML is that the processes of perception and imagination in the brain use almost the same neural mechanisms, just as the processes of representation and generation in neural networks use similar methods and architectures.<ref> G. Ganisa, W.L. Thompson, S.M. Kosslyn, Brain areas underlying visual mental imagery and visual perception: an fMRI Analysis, Cognitive Brain Research 20 (2004) 226–241.</ref> Furthermore, imagination and memory use similar mechanisms in the brain, so it is possible that computational models of imagination could help revolutionize computer memory and models of computer memory could improve our understanding of human episodic memory.<ref> Hassabis, D., Kumaran, D., & Maguire, E. A. (2007). Using imagination to understand the neural basis of episodic memory. Journal of neuroscience, 27(52), 14365-14374.</ref>

== Architectures Used to Implement Imagination in Machine Learning == 
[[File:Types of mental simulation in DL.png|500px|right|thumb|none|An overview of the types of models of mental simulation, illustrating how seemingly disparate cognitive phenomena are computationally quite similar. Blue circles indicate relevant observed variables, white circles indicate latent variables, pink circles indicate actions that modify states, and grayed-out circles indicate variables which are not relevant for a particular form of mental simulation. (a) Physical prediction tasks, where an initial observation is given (e.g. a tower of blocks) and future states are predicted given that observation (e.g. how the blocks move). (b) Mental rotation tasks can be seen as choosing a sequence of actions to produce mental images. (c) Theory of mind tasks involve inferring a latent state such as the preferences of another agent given a sequence of observations (e.g. that the agent picks up a pizza). (d) Reinforcement learning tasks, where  people must learn to choose actions to navigate through a sequence of symbols in order to maximize a reward.<ref> Hamrick 2019</ref>]]
This section reviews some of the most common and influential computational architectures that are used to implement or model imagination. These architectures almost always involve the use of ANNs. Hamrick (2019) reviews the way analogues of mental simulation and imagination are used in deep learning.<ref> Hamrick, J. B. (2019). Analogues of mental simulation and imagination in deep learning. Current Opinion in Behavioral Sciences, 29, 8-16. </ref> For example, in reinforcement learning mental models can be seen as a latent state representation of the [https://en.wikipedia.org/wiki/Markov_decision_process Markov decision process] that can simulated or run with mental actions, facilitating flexible and robust decisions based on rich models of the world. However, no current model of mental simulation can ''perfectly'' replicate the fast, precise, general, flexible, compositional, exploratory, and creative nature of human imagination. 

=== Reinforcement Learning ===
[[File:Agentenvironmentfeedbackloop.png|300px|thumb|right|A diagram of the structure of the agent-environment feedback loop in a Markov decision process, the problem type for reinforcement learning.]] 
[https://en.wikipedia.org/wiki/Reinforcement_learning Reinforcement learning] (RL) is an area of machine learning focused on creating intelligent agents that take actions in an environment to maximize reward. The agent's environment is usually modeled as a '''[https://en.wikipedia.org/wiki/Markov_decision_process Markov decision process]''' (MDP), where an agent at state ''s'' takes action ''a'', receives a reward ''r'', and then moves to a next state based on a transition function given by the environment dynamics. The agent must then attempt to map from observations to actions to maximize returns, with an incomplete knowledge of the environment's dynamics. In [https://en.wikipedia.org/wiki/Deep_reinforcement_learning deep reinforcement learning] (DRL), the agent uses [https://en.wikipedia.org/wiki/Deep_learning#Deep_neural_networks] deep artificial neural networks with many layers between input and output to process the complex states of the environment or represent the agent's action policy. In '''model-based RL''', the agent uses a forward model of the environment to predict the consequences and expected reward of actions, while ''model-free RL'' learns policies without modeling forward dynamics. 

[[File:imaginedtrajectories.png|300px|thumb|left|A visualization of the complex, branching future possible trajectories of an agent from an initial state. Simulating these trajectories assists the agent in choosing its path.]] 
Imagination is closely connected to planning, as both of these abilities involve an agent considering and evaluating possible sequences of actions in some domain to achieve some goal. (Although imagination is not necessarily goal-conditioned or action-focused, and can be aimless or 'wandering.') Therefore, imagination-type mechanisms are valuable for RL. Without good long-term planning, agents can run into flaws of their model, take actions that catastrophic failure, or fall into a local minimum that is difficult to escape. '''Supplementing RL agents with imagination''' allows them to incorporate predictions of the long-term future into their models, taking actions in an internal latent space to project their consequences and check if the decision model is current.<ref>Ke, N. R., Singh, A., Touati, A., Goyal, A., Bengio, Y., Parikh, D., & Batra, D. (2019). Learning dynamics model in reinforcement learning by incorporating the long term future. arXiv preprint arXiv:1903.01599.</ref>Agents might be able to adapt as quickly and effectively as humans if they understand the dynamics of their environments and can simulate the future to choose optimal actions. As early research by Rumelhart and Jordan (1992) shows, a multi-layer perceptron can replace the 'teacher' of supervised learning paradigms, allowing an adaptive agent to simulate its environment based on internal models.<ref> Jordan, M. I., & Rumelhart, D. E. (1992). Forward models: Supervised learning with a distal teacher. Cognitive science, 16(3), 307-354.</ref> Almost all uses of imagination in RL involve model-based deep reinforcement learning. These RL models often involve imagined '''rollouts,''' which are the simulation of the execution of a policy from a current state where future states are uncertain. Generating a series of rollouts for possible actions helps the agent find the value-maximizing action.

[[File:Bryavan imaginedrollouts.png|400px|thumb|right|Illustrates the imagined policy gradient computation implemented in Byravan et al (2020). Given a history H of observations from B, it encodes a latent state H, followed by an “imagined” rollout of length N using sequence of sampled actions. This leads to imagined states with corresponding value and reward estimates. The model averages cumulative rewards over N imagined horizons.]] 
Imagined trajectories can be used to estimate the value of action policies over time.<ref>Nauman, M., & Hengst, F. D. (2020). Low-Variance Policy Gradient Estimation with World Models. arXiv preprint arXiv:2010.15622.</ref> For example, Byravan (2020) implements a model-based RL algorithm based on a predictive model of expected future observations conditioned on the agent’s actions, deriving the agent's action policies based on gradient of estimated value along imagined trajectories.<ref> Byravan, A., Springenberg, J. T., Abdolmaleki, A., Hafner, R., Neunert, M., Lampe, T., ... & Riedmiller, M. (2020, May). Imagined value gradients: Model-based policy optimization with transferable latent dynamics models. In Conference on Robot Learning (pp. 566-589). PMLR.</ref> This approach uses a latent space model that allows predicting value as function of current policy even when the true system state is not observed, and can '''use imagined rollouts to achieve a stable learning policy''' rather than just observed trajectories. The model uses Stochastic Value Gradients (SVGs)<ref>Heess, N., Wayne, G., Silver, D., Lillicrap, T., Tassa, Y., & Erez, T. (2015). Learning continuous control policies by stochastic value gradients. arXiv preprint arXiv:1510.09142.</ref>, which enables re-evaluting rollouts with a learned model from off-policy data, accelerating learning through value gradients back-propagated through time. Byravan modifies SVGs to re-evaluate imagined rollouts in the latent space. This shows that imagination can be used by RL agents to estimate the value of their actions by projecting their future consequences.

A '''structure-based representation of the environment''' allows model-based RL to imagine future potential interactions between the agent and the environment. For instance, Guo et al (2020) uses a self-supervised representation learning algorithm to capture structured information about system dynamics and then make multistep predictions of future observations.<ref> Guo, Z. D., Pires, B. A., Piot, B., Grill, J. B., Altché, F., Munos, R., & Azar, M. G. (2020, November). Bootstrap latent-predictive representations for multitask reinforcement learning. In International Conference on Machine Learning (pp. 3875-3886). PMLR.</ref> 
Kielak (2019) presents an innovative architecture where GANs are used to model dynamics of the real environment, and then these models are used to artificially simulate the environment in an internal imagination module, preventing costly trial and error by simulating instead of testing. <ref>Kielak, K. (2019). Generative Adversarial Imagination for Sample Efficient Deep Reinforcement Learning. arXiv preprint arXiv:1904.13255.</ref> Similarly, Chiappa (2017) uses RNNs to make simulations of an image-based environment hundreds of time-steps into the future and enable an agent to effectively explore.<ref>Chiappa, S., Racaniere, S., Wierstra, D., & Mohamed, S. (2017). Recurrent environment simulators. arXiv preprint arXiv:1704.02254.</ref> In the '''Predictron''', an abstract model of an MDP rolls forward the environment in imagined steps, and then accumulates the internal rewards over these rollouts over different planning depths.<ref>Silver, D., Hasselt, H., Hessel, M., Schaul, T., Guez, A., Harley, T., ... & Degris, T. (2017, July). The predictron: End-to-end learning and planning. In International Conference on Machine Learning (pp. 3191-3199). PMLR.</ref> Then, the value of the trajectory over different planning depths is combined for an ensemble value. The agent can then update its policy based on the value of the trajectories imagined in its abstract internal space. Models can also be based on predicting the agent's own representations, rather than predicting the environment. These '''self-predictive representations''' involve training an agent to predict the state of its own latent space multiple steps into the future.<ref> Schwarzer, M., Anand, A., Goel, R., Hjelm, R. D., Courville, A., & Bachman, P. (2020). Data-efficient reinforcement learning with self-predictive representations. arXiv preprint arXiv:2007.05929.</ref> 

[[File:Worldmodelarchitecture.png|300px|thumb|right|The components of the Ha & Schmidhuber architecture, with three main components: (1) V: a visual component, compressing sensory info into a representation with a VAE, (2) M: a memory and prediction component implemented with a mixture density network and RNN, outputting a probability density function of the future, and (3) C: a controller for decision-making.]]
In Ha & Schmidhuber (2018), unsupervised generative recurrent NNs are used to model RL environments with compressed spatio-temporal representations.<ref> Ha, D., & Schmidhuber, J. (2018). Recurrent world models facilitate policy evolution. arXiv preprint arXiv:1809.01999.</ref>
Extracted features of model are then fed into simple evolution-trained policies. In a car-racing game, the agent was able to improve performance and make smoother turns by processing the track ahead in its internal imagination and predicting its own future moves. Further, the agent was able to model the game Doom and self-generate new levels, then train on this imagined level. The agent thus can be trained in an environment generated by its own internal world model and transfer the learned policy back to real world, showing that RL agents can '''learn inside their own dreams'''. Training in this simulated latent space can reduce training time by simplifying the environment to only the essential features, can improve training by amplifying difficulty in the virtual game, and can improve data efficiency by allowing the agent to generate any infinite number of trials. Similarly, '''Dreamer''' is a reinforcement learning agent that solves long-horizon tasks purely by latent imagination.<ref> Hafner, D., Lillicrap, T., Ba, J., & Norouzi, M. (2019). Dream to control: Learning behaviors by latent imagination. arXiv preprint arXiv:1912.01603.</ref> Dreamer efficiently learns optimal behaviors by learning a world-model and compressing it into a compact latent space, and out-performs all other models on 20 challenging visual control tasks. 

Another core problem in RL is the ''[https://en.wikipedia.org/wiki/Multi-armed_bandit exploit-explore tradeoff]'', where the agent must balance between pursuing known sources of reward or searching for new and potentially more rewarding pathways. Ideally, decision-making should take actions with the potential to optimize return far into the future. Seyde et al show that imagination can help solve this problem, implementing an architecture called '''LOVE (latent optimistic value exploration)'''.<ref>Seyde, T., Schwarting, W., Karaman, S., & Rus, D. (2020). Learning to Plan Optimistically: Uncertainty-Guided Deep Exploration via Latent Model Ensembles. arXiv preprint arXiv:2010.14641.</ref> In this approach, potential futures are imagined with latent models, and their performance is assessed with value function estimates over a finite horizon. Then, pathways with the highest predicted reward are pursued. This allows the agent to explore optimistically for optimal returns, without the risk of pursuing bad actions due to insufficient planning. An example of a similar approach is '''Plan2Explore''', where an agent plans out its actions in a self-supervised internal world model to seek out expected future novelty.<ref>Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D., & Pathak, D. (2020, November). Planning to explore via self-supervised world models. In International Conference on Machine Learning (pp. 8583-8592). PMLR.</ref> 

While almost all cases of imagination in RL are model-based, Hamrick (2017) implements one approach with only a minimal model.<ref>Hamrick, J. B., Ballard, A. J., Pascanu, R., Vinyals, O., Heess, N., & Battaglia, P. W. (2017). Metacontrol for adaptive imagination-based optimization. arXiv preprint arXiv:1705.02670.</ref> In this architecture, a metacontroller optimizes over ‘imagined’ internal simulations to make a more informed decision. At each time step, the agent (a robot) computes what this simulation-based control policy would do, but rather than executing these controls on the robot, it computes what the simulation expects the next state to be, and then decides which real-world action would achieve the next state based on its model of the environment dynamics. This approach is nearly model-free, since the models only simulate the next immediate step, are constantly updated based on an incoming stream of observations, and adapt their amount of computation to the difficulty of the task. 

==== Imagination-Augmented Agents ====

The imagination-augmented agent (I2A), as introduced by Racanière et al in 2017, is an architecture for deep reinforcement learning (DRL) that learns to interpret imagined trajectories from an internal model of the environment built by past observations, using these predictions as context for policy networks to construct implicit plans.<ref>Racanière, S., Weber, T., Reichert, D. P., Buesing, L., Guez, A., Rezende, D., ... & Wierstra, D. (2017, December). Imagination-augmented agents for deep reinforcement learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems (pp. 5694-5705).</ref> In this way, I2As can imagine the future to seek rewards and avoid painstaking trial-and-error. 

The '''architecture of the I2A''' involves several main components: 
# The '''imagination core''' is an environmental model that makes predictions about a future state given a current state and the agent's actions, rolling out a predicted trajectory multiple time-steps into the future. 
# '''Rollout encoders''' learn to interpret each imagined rollout of a future state, extracting the most useful information for the agent’s decision. This is to avoid over-reliance on simulated rewards alone, which can be in error. The encoders are implemented with [https://en.wikipedia.org/wiki/Long_short-term_memory#Idea long short-term memory] (LSTM), a type of recurrent neural network that can process entire data sequences. 
# An '''aggregator''' combines all of the rollout embeddings from the encoders into a single imagination code. 
# Finally, a '''policy module''' integrates the other components, comparing the model-based predictions from an imagined trajectories and the output of model-free path using a small network that only takes real observation as input, and returns an imagination-augmented policy and its estimated value. This involves calculating the loss function between the imagination-augmented policy computed on the current observation, and the model-free policy on the current observation. 

[[File:I2A_architecture.png|800px|thumb|center|A diagram of the architecture of I2A. (a) imagination core (IC) predicts next-time step conditioned on action sampled from rollout policy, (b) IC imagines trajectories encoded by rollout encoder, (c) rollout encodings & input from a model-free path are integrated to determine the output policy.]]

I2A is an innovative architecture that combines both model-free and model-based RL, using multiple parallel simulations to extract behaviorally useful info for the core model and imagined observations to supplement the model with additional information. Further, '''I2A solves the core limitations of model-based RL''': it usually requires extensive training on a large and tailored dataset, which reduces behavioral flexibility, impedes model generalization, is computationally expensive, and is often only possible when a model is easily available or learnable. Due to these issues, model-free RL is far more successful in complex, difficult-to-model domains. By using a model that simulates the environment, reinforcement-learning agents can interpret and act successfully based on imperfect and limited information. The I2A is also trained directly on low-level observations with little domain knowledge. 

The I2A agent was tested by playing [https://en.wikipedia.org/wiki/Sokoban Sokoban], a difficult procedurally-generated puzzle game that involves irreversibly pushing boxes to targets, requiring planning ahead and preventing easy model creation. This problem space poses unusual difficulties for both model-free and model-based RL. However, I2A achieved a shocking 82% success rate on this task, far '''better than any other existing RL strategy.'''<ref>Racanière et al 2017</ref> Although [https://en.wikipedia.org/wiki/Monte_Carlo_tree_search Monte Carlo Tree Search] algorithms are able to reach comparable performance as I2A, they require computing far more simulation steps - nearly 25x more steps than I2A. 

While I2A allows extracting information from imagined trajectories to improve an RL agent's planning, these trajectories are all generated by the same rollout policy and can therefore be homogenous and uninformative, leading to insufficient exploration. Liu et al (2019) '''extends the I2A framework''' to solve this problem, creating a model called E-I2A that uses an exploratory rollout policy.<ref>Liu, P., Zhao, Y., Zhao, W., Tang, X., & Yang, Z. (2019). An exploratory rollout policy for imagination-augmented agents. Applied Intelligence, 49(10), 3749-3764.</ref> In this modification, each imagined trajectory is optimized to be as novel as possible compared to the already-generated trajectories. This involves training an inverse dynamic model that predicts the agent's executed action given the current state and the next state, estimating an action's novelty by its unpredictability in this model. Then, the agent uses a distilled value function to calculate the value of imagined trajectories, and picks the trajectories with the highest value and novelty. E-I2A produces diversity in the imagined trajectories so they are more informative and novel, improving I2A's performance and data efficiency.

=== Variational Auto-encoders === 
A [https://en.wikipedia.org/wiki/Variational_autoencoder variational auto-encoder] (VAE) is a type of ANN that compresses the input information into a constrained latent model (encoding) to reconstruct it as accurately as possible (decoding). The VAE aims to minimize the difference between a given frame and the reconstructed version of the frame produced by the decoder, learning to input whatever is inputted and discovering an implicit representation of the input on the process. This implicit representation is called a '''[https://en.wikipedia.org/wiki/Latent_space latent space]''', a set of items embedded in manifold where similar items are closer together, allowing the algorithm learns structural similarities in the data. The dimensionality of the latent space is lower than the feature space. Thus, VAEs are often used to implement '''[https://en.wikipedia.org/wiki/Dimensionality_reduction dimensionality reduction]''', transforming high-dimensional data into a low-dimensional space without losing many meaningful properties. 

[[File:Latentspace.png|300px|thumb|right|An illustration of how an autoencoder reduces the dimensionality of an input to learn the latent space representation and reconstruct the image.<ref>Hackernoon, https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d</ref>]]

VAEs are useful in computational imagination, as they support creating efficient and accurate representations of the environment that can be used for generation or re-creation. An essential and early step in imaginative generation is '''[https://en.wikipedia.org/wiki/Feature_learning representation learning]''', the process of identifying the hidden representations and features in the data that enable classification from raw data. However, the primary limitation of VAEs is that they do not modify or combine these representations to create novel products. In practice, '''VAEs often serve as components of more complex architectures to implement imagination''', learning an implicit representation that is then taken up by other components. 

[[File:VQ-VAE encoderdecoder.png|300px|thumb|left|The VQ-VAE architecture, which encodes and decodes images using DNNs.]]
Razavi et al (2019) shows that a type of VAE, '''vector-quantized variational autoencoders (VQ-VAE)''', can generate synthetic image samples with high fidelity and diversity and a fast encoding-decoding speed, rivaling the best GANs and minimizing their shortcomings (primarily low output diversity).<ref> Razavi, A., van den Oord, A., & Vinyals, O. (2019). Generating diverse high-fidelity images with VQ-VAE-2. In Advances in neural information processing systems (pp. 14866-14876).</ref> In their model, an encoder (implemented in a deep neural network) maps the input space to a vector quantized by its distance to prototype vectors, which is then passed to a decoder that produces an image based on this encoding. This compresses the images into latent space representation 30x smaller than original image. 

[[File:VAErollouts.png|300px|thumb|right|A schematic of the SOLAR model, which uses a VAE to learn a representation for RL.]]
'''VAEs can also be used in RL problems''', where the agent must learn a latent state representing its environment to simulate the future. For example, the TD-VAE (temporal difference variational auto-encoder) uses a generative sequence model that learns representations containing explicit beliefs about states several steps into the future.<ref> Gregor, K., Papamakarios, G., Besse, F., Buesing, L., & Weber, T. (2018). Temporal difference variational auto-encoder. arXiv preprint arXiv:1806.03107.</ref> Furthermore, Nair et al (2018) creates an RL agent that employs a self-supervised practice phase, where it '''imagines goals and attempts to achieve them in a simulated space'''.<ref>Nair, A., Pong, V., Dalal, M., Bahl, S., Lin, S., & Levine, S. (2018). Visual reinforcement learning with imagined goals. arXiv preprint arXiv:1807.04742.</ref> This approach begins with representation learning with VAEs, which learn implicit structures in the environment to create a latent space for sampling goals and augmenting the input data. For a series of robot manipulation tasks, this method outperformed all others by a significant margin and was the only method able to find solutions on the hardest tasks. Finally, in Zhang et al's SOLAR model, a VAE is used to learn simple, regularized, and local models of an image-based environment.<ref> Zhang, M., Vikram, S., Smith, L., Abbeel, P., Johnson, M., & Levine, S. (2019, May). SOLAR: Deep structured representations for model-based reinforcement learning. In International Conference on Machine Learning (pp. 7444-7453). PMLR.</ref> This allows an agent to act based on compressed models of the environment and its near future.

=== Other Neural Network Architectures ===
This section cannot hope to exhaustively list all NN architectures that involve the imagination, but below is a sample of a few other models. 

==== Generative Adversarial Neural Networks ==== 
[[File:GAN diagram.png|400px|thumb|right|A schematic of the structure of a generative adversarial network.]]
[https://en.wikipedia.org/wiki/Generative_adversarial_network Generative adversarial networks] (GANs) involve two neural networks, using one neural network (the generator) to generate a sample based on its latent representation of the data and another network (discriminator) is used to assess or evaluate the generated samples based on criteria learned from the training data. The networks compete in a zero-sum game, where the generator wins if its generated output 'fools' the discriminator into evaluating it positively or classifying it as correct. 

GANs are particularly useful for computational imagination, as they support the proliferation of a huge number of novel possibilities as the generator seeks to exploit the discriminator. One example of an imagination-based GAN architecture is the '''Imaginative Adversarial Network''' (IAN), which involves integrating a 'cascade' of GANs together to combine a base set of data and a target set of data into novel combinations.<ref> Hamdi, A., & Ghanem, B. (2019). IAN: Combining Generative Adversarial Networks for Imaginative Face Generation. arXiv preprint arXiv:1904.07916.</ref> Further, GANs are also often used for data augmentation, where new synthetic data is imagined and used to train machine learning models further - although this data will not be entirely novel, but heavily biased by the sample data.<ref>Jain, N., Manikonda, L., Hernandez, A. O., Sengupta, S., & Kambhampati, S. (2018). Imagining an engineer: On GAN-based data augmentation perpetuating biases. arXiv preprint arXiv:1811.03751.</ref> Many more examples of GANs in imagination will be discussed in the Applications section. 

==== Long Short-Term Memory Networks ====
[https://en.wikipedia.org/wiki/Long_short-term_memory Long short-term memory] (LSTM) networks are a type of recurrent neural network (RNN) that can process sequences of data, and are typically composed of a cell that remembers values over time, and three gates that regulate the information flow in and out of the cell: an input gate, an output gate, and a forget gate. These networks can be especially useful for implementing imagination on time-series data, since LTSM networks support processing of information over time and solve the [https://en.wikipedia.org/wiki/Vanishing_gradient_problem vanishing gradient problem] that plagues most RNNs (where gradients computed using backpropagation can disappear over long-term periods). 

[[File:INNgenuity.png|400px|thumb|right|A diagram of the architecture of the INNGenuity system, where typical NN processing is complemented with a phase of clustering and two phases of alignment with a knowledge graph. The most meaningful signals (identified by semantic gates) are continually cached and clustered to maximize alignment.]]
For example, Oita (2019) introduces an architecture to implement useful imagination with interpretable deep learning mechanisms, called '''INNGenuity.'''<ref>Oita, M. (2019, March). Reverse engineering creativity into interpretable neural networks. In Future of Information and Communication Conference (pp. 235-247). Springer, Cham.</ref> This model is inspired by the neuroanatomy of creative cognition, creating ANN analogues of the imagination hub, salience hubs, and executive hubs of the human brain. It relies on adding '''semantic gates''' to a LSTM neural network, which creates meaningful divergence from existing representations by biasing the processing of input data at every step with relevant knowledge for the current layer. This involves recurrent connections, where higher-level info is fed back into earlier layers.

==== Deep Belief Networks ====
A [https://en.wikipedia.org/wiki/Deep_belief_network deep belief network] (DBN) is a kind of deep neural network that has multiple hidden layers with latent variables, with connections between the layers but not between units within each layer. These models can be seen as a combination of other simple, unsupervised neural networks, where these networks serve as the hidden layer of the DBN. 

An influential example of DBNs in computational imagination is Hinton et al (2006), to classify images of handwritten digits (0-9) by training on several examples and create a generative model of handwriting, and then used this to generatively “imagine" various possibilities for what a digit like 2 could looks like.<ref> Hinton, G.; Osindero, S.; and Teh, Y.-W. 2006. A fast learning algorithm for deep belief nets. Neural Computation 18(7):1527–1554. </ref> While DBNs are somewhat rare in actual implementations of imagination, they are one of the most effective neural network architectures for analyzing the brain activity of imagination using EEG data. For instance, DBNs were able to successfully classify what vowel sound people were imagining based only on EEG activity. <ref> Sree, R. A., & Kavitha, A. (2017, March). Vowel classification from imagined speech using sub-band EEG frequencies and deep belief networks. In 2017 fourth international conference on signal processing, communication and networking (ICSCN) (pp. 1-4). IEEE. </ref>Thus, DBNs can both model the imagination and support our neuroscientific understanding of imagination.

== Applications ==
Computational imagination has a wide variety of valuable applications. Below is an incomplete and broad list of some possible application areas.<ref>Partly based on a literature review in Setchi et al (2007)</ref> 

* Develop '''strategic thinking''' by creating and manipulating vivid projections of ambiguous environments. 
* Improve '''scenario planning''' by designing, conducting, and interpreting experiments in the imagination. 
* '''Learn new motor skills''' by supplementing motor training with mental training. 
* Better '''predict human behavior''' in unknown or hostile environments. 
* Assist in '''stimulating creative & innovative thinking''', supplementing the human creative process with artificial tools. 
* Help agents learn from experience and infer the behavioral causes of current states by '''constructing counterfactual scenarios'''. 
* Support '''empathy in computer systems''', enabling agents to understand human behavior and needs, informing appropriate actions and communications. 

Some specific selected applications of computational imagination are also reviewed in this section. 

=== Interactive search === 
[[File:Interactivesearch schematic.png|300px|left|thumb|none|A schematic of the interactive search process.]] 
Interactive search is one of the most common uses of artificial imagination, in which a '''user's initial query and later feedback are used to reorganize search results and synthesize new relevant options to supplement the results'''.<ref>Thomee, B., Huiskes, M. J., Bakker, E. M., & Lew, M. (2007, October). An artificial imagination for interactive search. In International Workshop on Human-Computer Interaction (pp. 19-28). Springer, Berlin, Heidelberg.</ref> This is especially useful in image search, where novel images can be created based on the user's expressed goals and feedback. Furthermore, human-in-the-loop artificial imagination systems can take a user's representation of their desired result in multiple forms (including images and sounds), attempt to guess what a user is imagining, and then refine the result to match the user's mental image based on subsequent feedback. <ref> Biswas, A., Pham, T. T., Vogelsong, M., Snyder, B., & Nassif, H. (2019, July). Seeker: Real-time interactive search. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (pp. 2867-2875).</ref> As computational models of human imagination improve, search engines will be better able to predict and replicate what users imagine, even if they are not able to describe their visualizations in words. Further, interactive search can be extended with '''synthetic imagery''', an advanced type of active learning where the system does not just actively ask the user for feedback on particular examples from the database to meet informational needs as well as possible, but also synthesizes new examples to directly meet informational requirements.<ref> Thomee, B., Huiskes, M. J., Bakker, E., & Lew, M. S. (2007, July). Visual information retrieval using synthesized imagery. In Proceedings of the 6th ACM international conference on Image and video retrieval (pp. 127-130).</ref> By giving the retrieval system the power to imagine, it can more quickly understand or generate what the user is looking for.

=== Learning video games === 
Learning complex games like the Atari video games often requires solving spatiotemporal prediction problems where future (image) frames are dependent on control variables or actions as well as previous frames. Oh et al (2015) demonstrate that two DNN architectures can use encoding, action-conditional transformation, and decoding layers to generate visually realistic future video game frames.<ref> Oh, J., Guo, X., Lee, H., Lewis, R., & Singh, S. (2015). Action-conditional video prediction using deep networks in atari games. arXiv preprint arXiv:1507.08750.</ref> World models are especially useful for understanding and predicting the dynamics of Atari-like video games.<ref> Hafner, D., Lillicrap, T., Norouzi, M., & Ba, J. (2020). Mastering atari with discrete world models. arXiv preprint arXiv:2010.02193.</ref>Furthermore, a forward simulation model using a CNN can accurately learn the dynamics of Super Mario Bros using video pixel input, and this model can be applied with a game-playing agent that imagines the consequences of its actions to improve performance.<ref> Guzdial, M., Li, B., & Riedl, M. O. (2017, August). Game Engine Learning from Video. In IJCAI (pp. 3707-3713). </ref>Go, a game that requires processing a huge number possibilities and probabilities, has frequently been used as a test for machine learning systems. Silver et al (2016) demonstrate that imagination can be fruitfully applied to this problem, creating a system with two DNNs: (1) policy network that imagines the future conditioned by a current move and anticipates the set of possible moves most likely to win, and (2) a value network that evaluates the winner in each position by searching ahead a few possibilities.<ref> Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., ... & Hassabis, D. (2016). Mastering the game of Go with deep neural networks and tree search. Nature, 529(7587), 484-489.</ref> By executing thousands of simulated rollouts per second, this model facilitates superhuman gameplay of Go.

=== Robots and autonomous navigation ===
[[File:Forwardmodels diagram.png|300px|left|thumb|none|A diagram of the chained forward model architecture used in Hoffman & Möller (2004).]] 
Robots and other agents that perform autonomous navigation employ '''goal-directed planning''', which requires search in a high-dimensional motor space defined by sequence of movements. Imagination is often useful in this planning. For instance, Hoffman & Möller (2004) chain together a series of forward models (implemented with multi-layer perceptrons) which simulate how a sensory situation changes as result of agent’s actions, allowing a robot to perform goal-directed movements in a real environment.<ref> Hoffmann, H., & Möller, R. (2004). Action selection and mental transformation based on a chain of forward models. From Animals to Animats, 8, 213-222.</ref> The mobile robot also exhibits mental simulation, using the forward model to predict the sensory changes resulting from action commands without executing any actions. Hoffman (2007) extends this approach, using a robot that predicts future visual input and uses simulated movement to understands properties of environment, (1) judging distance by simulating straight walking, and (2) recognizing dead-ends with a simulated search for an exit. <ref> Hoffmann, H. (2007). Perception through visuomotor anticipation in a mobile robot. Neural Networks, 20(1), 22-33.</ref> A mobile robot equipped with a deep neural network can perform off-line (simulated) learning of mapping relations between visual perceptions and motor sequences.<ref> Banjanovic-Mehmedovic, L., Dzenisan, G., Mehmedovic, F., & Havic, J. (2011, October). Neural learning behavior of mobile robot by visually based sequence of actions. In 2011 XXIII International Symposium on Information, Communication and Automation Technologies (pp. 1-7). IEEE.</ref> '''NeoNav''' is a framework for robot navigation that outperforms other state-of-the-art models,  where an agent is guided by predicting the next observations it expects to see with a NN-based variational Bayesian model.<ref>Wu, Q., Manocha, D., Wang, J., & Xu, K. (2020, April). Neonav: Improving the generalization of visual navigation via generating next expected observations. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 06, pp. 10001-10008).</ref> Robots can even '''learn effective real-world visuomotor policies by interacting with a dreamed model''' rather than the sensory environment. <ref> Piergiovanni, A. J., Alan Wu, and Michael S. Ryoo. "Learning real-world robot policies by dreaming." In 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 7680-7687. IEEE, 2019.</ref> 

Robot manipulation also rarely has access to ground-truth signals of rewards or environmental factors, and so '''predictions based on incomplete information''' are necessary. Ebert et al (2018) shows that a self-supervised model-based RL approach can predict the future based on raw readings from a robot's sensors, using deep predictive models trained without human input can generalize to never-seen objects and improve vision-based robotic control.<ref>Ebert, F., Finn, C., Dasari, S., Xie, A., Lee, A., & Levine, S. (2018). Visual foresight: Model-based deep reinforcement learning for vision-based robotic control. arXiv preprint arXiv:1812.00568.</ref> This kind of simulated interaction with the environment might also support motor perception in humans, and explain why kittens that grew up only being moved passively have impaired movement and depth perception - they are unable to simulate their own future movements.<ref> Harris, C. S. (2014). The Development of Visually Guided Behavior. In Visual Coding and Adaptability (pp. 61-78). Psychology Press. </ref> '''Giving robots an internal world model''', an embedded simulation of itself and its surrounding environment, allows them to develop functional self-awareness that facilitates safer and more appropriate actions.<ref> Winfield, A. F. (2014). Robots with internal models: a route to self-aware and hence safer robots.</ref> '''Imagination-augmented robots''' have the capacity to test what-if hypotheses, simulating future consequences of actions without actually carrying them out. A simulator module allows the robot to imagine alternative sequences of motor actions and find the one that best achieves the goal. 

[[File:Dreamer performance horizon.png|200px|left|thumb|none|A graph of Dreamer's performance on the car-racing task compared to other ML models.]]
[[File:Dreamer performance horizon.png|200px|right|thumb|none|A graph of Dreamer's performance as a function of its imagination horizon.]] 
Brunnbauer et al (2021) apply '''model-based imagination-augmented reinforcement learning to an autonomous race car task''', showing that agents capable of learning in imagination substantially outperform model-free agents with respect to performance, sample efficiency, successful task completion, and generalization.<ref>  Brunnbauer, A., Berducci, L., Brandstätter, A., Lechner, M., Hasani, R., Rus, D., & Grosu, R. (2021). Model-based versus model-free deep reinforcement learning for autonomous racing cars. arXiv preprint arXiv:2103.04909.</ref> They create a world model called '''Dreamer''', which learns a representation of the state-space model of the racing track from high-dimensional input observations, and then use it as a predictive model to train policies for long-horizon visual control tasks in imagination. It also applies a generative-evaluative cycle with an actor-critic algorithm to train the agent, where an action model creates a projected optimal action and a value model estimates the value of each action state. A longer '''imagination horizon,''' simulating the future farther, generally improved Dreamer's performance up to a threshold.

==== Ethical robots ==== 
[[File:Ethicalrobot internalsimulation.png|500px|right|thumb|none|The architecture for an ethical robot with internal simulation from Vanderelst & Winfield (2018).]] 
Many insist that intelligent autonomous robots need to be not just safe, but explicitly ethical. '''Functional imagination can support the development of ethical robots''', which use internal simulations to simulate actions & predict their consequences, allowing them to test possible actions without committing to them. This way, the robot does not have to test out potentially harmful actions, and can identify and preempt unethical behavior by simulating it beforehand. Vanderelst & Winfield (2018) demonstrate this with a four-layered robot controller: (1) generate long-term goals, (2) produce a set of executable tasks, (3) translate tasks into motor actions, (4) an ethical layer that evaluates each action before execution, distributed across the other layers.<ref> Vanderelst, D., & Winfield, A. (2018). An architecture for ethical robots inspired by the simulation theory of cognition. Cognitive Systems Research, 48, 56-66.</ref> The ethical layer relies on a simulator initialized with the current state, which simulates and ethically evaluates the consequences of alternative actions. They then test this robot to show that it obeys [https://en.wikipedia.org/wiki/Three_Laws_of_Robotics Asimov's three laws of robotics], acting ethically and refusing to do harm to humans even against explicit orders. Imagination can therefore be used to develop ethical robots, which may even be able to exhibit super-human ethical reasoning - humans are likely only to consider a few highly-available options because of cognitive limits, while ANN-equipped robots can consider more possibilities.

=== Mechanical reasoning and architecture ===
[[File:Imaginedarchitecture.png|400px|left|thumb|none|Examples of imagined, ANN-generated architectural structures.]]
Several experiments support the idea that mechanical reasoning (deriving info about how things move) is carried out by mental simulation, where people transform spatial relations and carry out causal chains of physical events using mental imagery.<ref> Hegarty, M. (2004). Mechanical reasoning by mental simulation. Trends in cognitive sciences, 8(6), 280-285.</ref> This suggests that computational models of physical systems could also be improved by adding in internal simulation or imagination. Applying artificial imagination to mechanical reasoning problems could enable physical robots to more effectively interact with and predict their environments. This could also be useful in modeling architecture: deep CNNs can imagine architecture by developing a shape grammar, a learned representation of architectural styles, materials, and structural systems extracted from example buildings, allowing the network to recombine architectural elements in novel and creative ways. <ref> Silvestre, J., & Ikeda, Y. (2016). Artificial imagination of architecture with deep convolutional neural network. In Proceedings of the 21st International Conference of the Association for Computer-Aided Architectural Design Research in Asia CAADRIA 2016, 881–890.</ref> Adding a simulation-based mechanical reasoning component to generative architecture would enable more dynamic and full-spectrum models of buildings.

[[File:Visual interaction network.png|300px|right|thumb|none|A diagram of the visual interaction network architecture.]]
Watters et al (2017) demonstrate '''Visual Interaction Networks''' (VINs), a general-purpose model for learning the dynamics of physical system with raw perceptual observations, using a perceptual front-end with CNNs to learn latent representation and a dynamics predictor with interaction networks to roll forward in time for simulations of the future.<ref> Watters, N., Tacchetti, A., Weber, T., Pascanu, R., Battaglia, P., & Zoran, D. (2017). Visual interaction networks. arXiv preprint arXiv:1706.01433.</ref> This model can use just six image frames to generate accurate future trajectories of over 100 time steps for a wide range of physical systems, including systems with invisible objects or properties. Equipping robots with these VINs could enhance their ability to understand and predict physical interactions and environments. 

=== Empathy and social cognition === 
As we increasingly spend time interacting with artificial systems, there is a growing demand for 'empathetic computers' that can understand and respond to human mental states and affects. Studies on human-computer interaction demonstrate that affective agents can reduce user frustration.<ref>Hone, K. (2006). Empathic agents to reduce user frustration: The effects of varying agent characteristics. Interacting with computers, 18(2), 227-245.</ref> Despite the need for empathetic systems, there has been comparatively little progress on implementing empathy in ANNs. However, a few advancements have been made. 

Facial expression recognition is a critical process that enables empathy, and this task can be supported by the substantial and burgeoning research on [https://en.wikipedia.org/wiki/Computer_vision computer vision]. Existing facial recognition models use several different technical approaches, including using discriminative models to associate facial images to specific emotions, constructing deterministic causal models of the anatomy of the human face, and creating artificial neural networks to learn implicit representations of face dynamics and their affective meanings.<ref> Lisetti, C. L., & Schiano, D. J. (2000). Automatic facial expression interpretation: Where human-computer interaction, artificial intelligence and cognitive science intersect. Pragmatics & cognition, 8(1), 185-235. </ref> ANNs are especially suited to this task because they can handle the noisy, partial, and complex data about human faces.

Another important step in developing theory of mind is understanding human common-sense. Lockerd (2019) models commonsense as redundant shared experience over time, and shows computers can learn this shared experience from humans in video games, and then predict commonsense future events with imagined simulations.<ref>Lockerd, A. L. (2009). Acquiring Commonsense Through Simulation. Unpublished White Paper,<http://web. media. mit. edu/~ alockerd/papers/CommonsenseSimulation. pdf>, Accessed, 23.</ref>

=== Creative generation ===
Imagination is amazingly effective in generating creative artifacts in a wide range of modalities, from artificial visual art and video to AI-generated short stories and audio composition. 

==== Text generation ==== 
ANNs have been harnessed to imagine narratives and express them in text. For example, '''ScriptWriter''' is a system based on CNNs that performs text processing, semantic extraction and animation planning, and can develop believable imagined agents that play roles in an imagined world, combining these capacities to '''imagine short stories''' with primitive objects like scenes and characters. <ref> Astakhov, V., Astakhova, T., & Sanders, B. (2006). Imagination as Holographic Processor for Text Animation. arXiv preprint cs/0606020.</ref> Another example is Pérez & Sharples (2001)'s '''MEXICA''', a computer model that produces short stories, generating material guided by content and rhetorical constraints, avoiding the use of explicit goals or story-structure information, and evaluates the novelty and interestingness of the story as it progresses and verifies that coherence requirements are satisfied.<ref> PÉrez, R. P. Ý., & Sharples, M. (2001). MEXICA: A computer model of a cognitive account of creative writing. Journal of Experimental & Theoretical Artificial Intelligence, 13(2), 119-139.</ref> Text generation will often be more effective when a human is in the loop to add suggestions, feedback, and ideas. For example, Manjavacas et al (2017) show that an AI system with a GUI that enables writers to give suggestions can produce excellent science fiction stories in a co-creative process.<ref> Manjavacas, E., Karsdorp, F., Burtenshaw, B., & Kestemont, M. (2017, September). Synthetic literature: Writing science fiction in a co-creative process. In Proceedings of the Workshop on Computational Creativity in Natural Language Generation (CC-NLG 2017) (pp. 29-37).</ref> 

==== Image, scene, and video generation ==== 
One of the most widespread but remarkable applications of imagination-based ANNs is in generating creative visual artifacts and artificial art pieces. One of the most remarkable abilities of imagination-augmented ANNs is '''generating new images based on text descriptions'''. For instance, DARCI is a system composed of hundreds of neural networks that implements artistic imagination, creating novel images to communicate a list of conceptual adjectives (and even non-adjectives). <ref> Norton, D., Heath, D., & Ventura, D. (2013). Finding creativity in an artificial artist. The Journal of Creative Behavior, 47(2), 106-124.</ref> DARCI also uses [https://en.wikipedia.org/wiki/Evolutionary_algorithm evolutionary algorithms] to refine the generated image, where the human aesthetic sense acts as the fitness function that decides which phenotypes (produced images) are passed onto the next generation. This does not require a human-in-the-loop, but rather uses a generalized aesthetic sense trained by analyzing thousands of interactions where humans associated images with adjectives and flagged DARCI's incorrect associations. Vismatic is a similar semi-automatic system that generates visual compositions to express specific meanings, using conceptual and visual creativity to find visual solutions - figuring out what visually.<ref> Xiao, P., & Linkola, S. M. (2015, June). Vismantic: Meaning-making with images. In Proceedings of the Sixth International Conference on Computational Creativity. Brigham Young University.</ref> Vismatic is able to use higher level image analysis to understand how interactions between elements in a picture produces meaning, and combine images with juxtaposition, replacement, and fusion to produce expressive, diverse, and surprising image ideas according to human assessors. 

[[File:GQN diagram.png|400px|left|thumb|none| See how GQN works above: (A) observes training scene from different viewpoints, (B) inputs these observations into representation network that creates scene representation, then generation network (recurrent latent variable model) predicts scene from different queried viewpoints.]]
Image-generation capabilities can be combined and augmented to render and '''imagine entire scenes'''. The '''Generative Query Network (GQN)''' is a model that does not require millions of images pre-labeled by humans to recognize scene elements.<ref> Eslami, S. A., Rezende, D. J., Besse, F., Viola, F., Morcos, A. S., Garnelo, M., ... & Hassabis, D. (2018). Neural scene representation and rendering. Science, 360(6394), 1204-1210.</ref> Instead, GQN takes pictures from different viewpoints to create a simplified abstract description (internal world model) and predict the scene from any arbitrary viewpoint (imagine alternative points of view). GQN is based on two components: (1) a representation network that takes observations and produces representation of the scene, (2) a generation network that predicts or imagines the scene from new viewpoints. It can imagine unobserved scenes with remarkable precision, without prior knowledge of the laws of perspective, occlusion, or lighting. This capacity can also be used to support RL agents with a near-innate understanding of their environment and the scenes that compose it. '''PixelCNN''' is a convolutional neural network that models the joint distribution of pixels over an image to generate diverse, realistic scenes including faces, animals, landscapes, structures, and/or faces, and predict future scenes conditioned on current states and actions.<ref> Oord, A. V. D., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., & Kavukcuoglu, K. (2016). Conditional image generation with PixelCnn decoders. arXiv preprint arXiv:1606.05328.</ref> <ref>Oord, A. V. D., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., & Kavukcuoglu, K. (2016). Conditional image generation with PixelCnn decoders. arXiv preprint arXiv:1606.05328.</ref>ANNs can also support imagining dynamic moving scene videos, not just static scene images. Vondrick et al (2016) shows that a GAN with a spatio-temporal convolutional architecture can use a lrge set of unlabeled videos to learn a model of scene dynamics for both video recognition and generation.<ref>Vondrick, C., Pirsiavash, H., & Torralba, A. (2016). Generating videos with scene dynamics. Advances in neural information processing systems, 29, 613-621</ref> This model was able to learn how environments transform over time and produce plausible videos of scenes. 

==== Audio and music generation ====
[[File:Jukebox architecture.png|500px|left|thumb|none|A diagram of the Jukebox architecture, with three separate VQ-VAE models with different temporal resolutions. Input audio is encoded into latent vectors h(t), then a decoder takes these vectors and reconstructs the audio.]]
ANNs are also applied to generate novel audio sequences. Processing and modelling audio is exceptionally difficult, since the meanings of audio often depend on long-range dependencies not visible at lower-levels, and audio is informationally dense and computationally expensive - a 4 min audio segment has 160 million bits of info while a 1024x1024 RGB image has only 72 million bits.<ref> Dhariwal et al (2020)</ref> Audio generation employs a wide variety of computational architectures. The first computer-generated music used Markov chains in 1957, and this approach has been continued to thsi day.<ref> Shapiro, I., & Huber, M. (2021). Markov Chains for Computer Music Generation. Journal of Humanistic Mathematics, 11(2), 167-195.</ref> '''DeepBach''' is a graphical model for modeling polyphonic music and specifically hymn-like pieces, using Gibbs sampling to generate highly convincing chorales in the style of Bach, which can also be guided by human input.<ref> Hadjeres, G., Pachet, F., & Nielsen, F. (2017, July). Deepbach: a steerable model for bach chorales generation. In International Conference on Machine Learning (pp. 1362-1371). PMLR.</ref> '''MidiNet and MuseGAN''' employ GANs to generate artificial music, demonstrating that the system can generate chords, arpeggios or melodies of up to four bars without human inputs.<ref> Dong, H. W., Hsiao, W. Y., Yang, L. C., & Yang, Y. H. (2018, April). Musegan: Multi-track sequential generative adversarial networks for symbolic music generation and accompaniment. In Thirty-Second AAAI Conference on Artificial Intelligence.</ref><ref> Yang, L. C., Chou, S. Y., & Yang, Y. H. (2017). Midinet: A convolutional generative adversarial network for symbolic-domain music generation. arXiv preprint arXiv:1703.10847.</ref> MuseNet and Music Transformer use [https://en.wikipedia.org/wiki/Transformer_(machine_learning_model) Transformers], a deep learning model that weights the significance of each part of the input data, to learn musical styles and blendi them together in novel ways to generate multiple minutes of multi-instrument music.<ref> Topirceanu, A., Barina, G., & Udrescu, M. (2014, September). Musenet: Collaboration in the music artists industry. In 2014 European Network Intelligence Conference (pp. 89-94). IEEE.</ref><ref> Huang, C. Z. A., Vaswani, A., Uszkoreit, J., Shazeer, N., Simon, I., Hawthorne, C., ... & Eck, D. (2018). Music transformer. arXiv preprint arXiv:1809.04281.</ref> 

Finally, one of the most prominent examples of audio generation is Jukebox, a generative model for music that uses VAEs to compress raw audio into discrete codes, then model these codes with autoregressive sparse transformers trained over the compressed representation of the audio space.<ref> Dhariwal, P., Jun, H., Payne, C., Kim, J. W., Radford, A., & Sutskever, I. (2020). Jukebox: A generative model for music. arXiv preprint arXiv:2005.00341.</ref> Jukebox is able to generate coherent, meaningful, and human-approved music sequences. 

=== Commercial applications ===
Artificial imagination clearly has a huge number and diversity of use-cases. However, it is not yet commonly used in the broader economy. One commercial application of artificial imagination is CausalLens, a company that attempts to use ML models to explore counterfactuals, imagine possibilities and, explain past events.<ref> CausaLens, Towards Artificial Imagination. <https://www.causalens.com/white-paper/towards-artificial-imagination/.> </ref> Often, identifying the root cause of an event requires counterfactual inference. For example, many possible factors could cause solar panels to fail, but by 'imagining' alternative possibilities, a model can answer hypothetical what if questions like "if the humidity levels were lower, would the solar panels have failed?" CausalLens claims to use a structural equation model and ANNs to encode qualitative and quantitative aspects of cause-effect relationships in the manufacturing environment, assessing how millions of decisions and factors in project can contribute to its success or failure.

== Conclusions and Implications == 
=== Imagination and AI research === 
The field of [https://en.wikipedia.org/wiki/Artificial_intelligence artificial intelligence research] has primarily focused on logical models, but this approach has resulted in stagnating progress as these systems fail to exhibit resourcefulness and creativity in novel environments.<ref>Setchi et al 2007</ref> Oleinik (2019) argues that the current focus on statistical regression limits possibilities for artificial creativity, as this only supports recognizing patterns and making classifications based on structured training data, and is less capable of generation and prediction.<ref> Oleinik, A. (2019). What are neural networks not good at? On artificial creativity. Big Data & Society, 6(1), 2053951719839433.</ref> '''Creativity requires the opposite of training a network - it is something that shakes the neural network's ordinary operation''' by altering connection weight values with creative shocks, undermining the ‘normal’ functioning of the model. This is similar to the way creativity in humans involves the co-activation and communication between regions of the brain that ordinarily are not strongly connected. Replicating this kind of surprising, creativity-enabling positive disintegration of existing representations will be difficult to replicate in neural networks.  However, the review of existing models above shows that the research is progressing quickly and is already able to emulate human creativity at a surprising level. Still, most progress has been achieved in building domain-specific neural networks, and artificial intelligence and imagination will require creating mega-neural networks that connect domain-specific ones together for general-purpose tasks. 

Ultimately, integrating the imagination into AI research may allow breakthroughs in creating adaptable systems and replicating human-level intelligence.<ref>Kunda, M. (2018). Visual mental imagery: A view from artificial intelligence. Cortex, 105, 155-172. </ref> Artificial imagination can support AI research while AI research supports progress in the imagination. The human brain is not entirely logical, and thus adding creativity, imagination, and emotions into artificial systems can enable more accurate simulations of human cognition. Computers with faster processing speeds and more working memory than humans may even be able to represent more imagined entities simultaneously than the human brain, and thus could have ''''superhuman imaginations.'''' It may be the case that "enabling imagination in artificial agents is the ultimate resource to be developed in order to further expand our ability to understand the world."<ref>Oita, M. (2019, March). Reverse engineering creativity into interpretable neural networks. In Future of Information and Communication Conference (pp. 235-247). Springer, Cham.</ref>. Furthermore, this process may help answer philosophical questions about whether symbol-manipulating machines can be creative.<ref> McGregor, Stephen, Geraint A. Wiggins, and Matthew Purver. "Computational Creativity: A Philosophical Approach, and an Approach to Philosophy." In ICCC, pp. 254-262. 2014.</ref>Successful artificial imagination requires both decomposing reality into good representations and using these models to generate novel and useful objects or representations. Therefore, in the process of developing it, we will gain a deeper understanding of ourselves, our computational tools, and our world.

=== Social and ethical consequences ===
[[File:Creativeprocesses threats.png|300px|right|thumb|none|A diagram of the elements of creative processes and the threats to them.]]
Research on computational imagination also of course has '''economic and societal implications'''. In fact, some argue that we are beginning to enter an '''[https://en.wikipedia.org/wiki/Imagination_age imagination age]''', in which creativity and imagination are the main sources of economic value, virtual reality is widespread, and almost all people will be engaged in some form of content-creation for a global [https://en.wikipedia.org/wiki/Metaverse metaverse]. In economies centered around imagination, the knowledge workers of the [https://en.wikipedia.org/wiki/Information_Age information age] will be replaced by creative workers, and more straightforward information processing and logical thinking will be outsourced to either other economies or to computers.  Simultaneous advances in machine learning, nanotechnology, biotechnology, communication, and virtual reality could enable human creativity on a level never before seen.<ref> Magee, C. (1993). The Age of Imagination: Coming Soon to a Civilization Near You. In Second International Symposium: National Security & National Competitiveness: Open Source Solutions (Vol. 1).</ref> By augmenting human creative capabilities and supplementing them with imaginative ANNs, the development of artificial imagination could accelerate this socio-economic transformation.

Developing artificial imagination also has '''important ethical implications'''. Creativity is good for individual and social well-being in the long term. However, current mainstream AI tends to be anti-creative, in that it is trained based on limited repositories of highly structured data and often aims to maximize a narrowly-defined utility function.<ref>Loi, M., Viganó, E., & van der Plas, L. (2020). The societal and ethical relevance of computational creativity. arXiv preprint arXiv:2007.11973.</ref> This means that there are moral risks and costs of employing this type of AI in human endeavors. They are biased by their limited structured data, often in problematic ways. As these systems increasingly influence decision-making in society, they will taint and impoverish their own training data, as the future data will be shaped by their own expectations and structures. Further, using uncreative AI systems to influence human decision-making and recommendations will place soft limits on human freedom, encouraging stagnation, reducing openness, and constraining the possibility to experiment by preempting the appearance of unexpected options, thereby reducing human well-being. '''Developing computational systems that integrate imagination and creativity can help prevent these damaging ethical potentialities''', promoting computational tools that support well-being, freedom, and self-exploration rather than impairing it.

== References ==
